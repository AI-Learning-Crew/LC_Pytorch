# LC_PyTorch - ì–¼êµ´ ì¶”ì¶œ, ì¤‘ë³µ ì œê±° ë° ì–¼êµ´-ìŒì„± ë§¤ì¹­ í”„ë¡œì íŠ¸

ì´ í”„ë¡œì íŠ¸ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì–¼êµ´ì„ ì¶”ì¶œí•˜ê³ , ì¤‘ë³µëœ ì–¼êµ´ì„ ì œê±°í•˜ì—¬ ê³ ìœ í•œ ì¸ë¬¼ë³„ë¡œ ê·¸ë£¹í™”í•˜ë©°, ì–¼êµ´ê³¼ ìŒì„±ì„ ë§¤ì¹­í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤. **VoxCeleb ë°ì´í„°ì…‹ì„ ìœ„í•œ ì „ìš© ëª¨ë“ˆë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.**

## ì£¼ìš” ê¸°ëŠ¥

1. **ì–¼êµ´ ì¶”ì¶œ**: ë¹„ë””ì˜¤ íŒŒì¼ì˜ ì²« í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì¶”ì¶œ
2. **ì–¼êµ´ ì¤‘ë³µ ì œê±°**: ì–¼êµ´ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ë™ì¼ ì¸ë¬¼ì„ ì‹ë³„í•˜ê³  ê·¸ë£¹í™”
3. **ëŒ€í‘œ ì–¼êµ´ ì„ íƒ**: ê° ì¸ë¬¼ ê·¸ë£¹ì—ì„œ ëŒ€í‘œ ì–¼êµ´ì„ ì„ íƒí•˜ì—¬ ë³„ë„ ì €ì¥
4. **ì–¼êµ´-ìŒì„± ë§¤ì¹­**: ViT + Wav2Vec2 ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ë¡œ ì–¼êµ´ê³¼ ìŒì„± ë§¤ì¹­
5. **VoxCeleb ì „ìš© ëª¨ë“ˆ**: HQ VoxCeleb ë°ì´í„°ì…‹ì„ ìœ„í•œ ìµœì í™”ëœ ë°ì´í„°ì…‹ ë° ëª¨ë¸
6. **ëª¨ë¸ í‰ê°€**: Top-K ì •í™•ë„, ROC-AUC ë“± ë‹¤ì–‘í•œ ì„±ëŠ¥ ì§€í‘œ ì œê³µ

## ì„¤ì¹˜

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. DeepFace ì„¤ì¹˜ (ì„ íƒì‚¬í•­)

ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ„í•´ DeepFaceë¥¼ ë³„ë„ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
git clone https://github.com/serengil/deepface.git
cd deepface
pip install -e .
```

## ì‚¬ìš©ë²•

### 1. ì–¼êµ´ ì¶”ì¶œ ë° ì¤‘ë³µ ì œê±°

#### ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

```bash
python train.py --dataset_path /path/to/videos --output_base_dir /path/to/output
```

#### ë‹¨ê³„ë³„ ì‹¤í–‰

```bash
# ì–¼êµ´ ì¶”ì¶œë§Œ
python scripts/extract_faces.py \
    --dataset_path /path/to/videos \
    --output_dir /path/to/extracted_faces \
    --detector_backend retinaface

# ì¤‘ë³µ ì œê±°ë§Œ
python scripts/deduplicate_faces.py \
    --faces_dir /path/to/extracted_faces \
    --dedupe_dir /path/to/deduped_faces \
    --representative_dir /path/to/representative_faces \
    --model_name Facenet \
    --threshold 0.4
```

### 2. ì–¼êµ´-ìŒì„± ë§¤ì¹­ ëª¨ë¸

#### ì¼ë°˜ ë°ì´í„°ì…‹ìš© ëª¨ë¸ í•™ìŠµ

```bash
python scripts/train_face_voice.py \
    --image_folder /path/to/face/images \
    --audio_folder /path/to/audio/files \
    --save_dir /path/to/save/model \
    --batch_size 32 \
    --num_epochs 100 \
    --learning_rate 1e-4
```

#### ì¼ë°˜ ë°ì´í„°ì…‹ìš© ëª¨ë¸ í‰ê°€

```bash
python scripts/evaluate_face_voice.py \
    --image_folder /path/to/face/images \
    --audio_folder /path/to/audio/files \
    --model_dir /path/to/saved/model \
    --test_size 0.05 \
    --top_k 5
```

### 3. HQ VoxCeleb ë°ì´í„°ì…‹ ì „ìš©

#### ë°ì´í„° ë¶„í•  ìƒì„±

```bash
python scripts/hq/create_hq_voxceleb_split.py \
    --vox_dir ./data/HQVoxCeleb \
    --output_json ./data/HQVoxCeleb/split.json
```

#### HQ VoxCeleb ëª¨ë¸ í•™ìŠµ (CPU)

```bash
export KMP_DUPLICATE_LIB_OK=TRUE
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
python scripts/hq/train_hq_voxceleb.py \
    --save_dir ./saved_models/hq_voxceleb \
    --force_cpu \
    --batch_size 8 \
    --num_epochs 10
```

#### HQ VoxCeleb ëª¨ë¸ í•™ìŠµ (GPU)

```bash
python scripts/hq/train_hq_voxceleb.py \
    --save_dir ./saved_models/hq_voxceleb \
    --batch_size 16 \
    --num_epochs 50
```

#### HQ VoxCeleb ëª¨ë¸ í‰ê°€

```bash
python scripts/hq/evaluate_hq_voxceleb.py \
    --model_dir ./saved_models/hq_voxceleb \
    --force_cpu
```

### 4. Google Colabì—ì„œ ì‚¬ìš©

```python
# Google Drive ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# ì–¼êµ´ ì¶”ì¶œ ë° ì¤‘ë³µ ì œê±°
!python train.py \
    --dataset_path /content/drive/MyDrive/myProject/pjt_face_voice/face_video_5k \
    --output_base_dir /content/drive/MyDrive/myProject/pjt_face_voice/face_video_5k_processed

# ì–¼êµ´-ìŒì„± ë§¤ì¹­ ëª¨ë¸ í•™ìŠµ
!python scripts/train_face_voice.py \
    --image_folder /content/drive/MyDrive/myProject/pjt_face_voice/face_video_5k_representative_faces_manu \
    --audio_folder /content/drive/MyDrive/myProject/pjt_face_voice/face_video_5k_representative_faces_manu_audio_wav \
    --save_dir /content/drive/MyDrive/myProject/pjt_face_voice/saved_models_InfoNCELoss_batch64_100epoch_ViT

# HQ VoxCeleb ëª¨ë¸ í•™ìŠµ
!python scripts/hq/train_hq_voxceleb.py \
    --save_dir /content/drive/MyDrive/myProject/pjt_face_voice/hq_voxceleb_model
```

## ë§¤ê°œë³€ìˆ˜ ì„¤ëª…

### ì–¼êµ´ ì¶”ì¶œ ë§¤ê°œë³€ìˆ˜

- `--dataset_path`: ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
- `--output_dir`: ì¶”ì¶œëœ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
- `--detector_backend`: ì–¼êµ´ ê°ì§€ê¸° ë°±ì—”ë“œ
  - `opencv`: OpenCV Haar Cascade
  - `ssd`: Single Shot Detector
  - `dlib`: Dlib CNN
  - `mtcnn`: MTCNN
  - `retinaface`: RetinaFace (ê¸°ë³¸ê°’)
  - `mediapipe`: MediaPipe
- `--align_faces`: ì–¼êµ´ ì •ë ¬ ê¸°ëŠ¥ í™œì„±í™” (ê¸°ë³¸ê°’: True)
- `--video_extensions`: ì²˜ë¦¬í•  ë¹„ë””ì˜¤ íŒŒì¼ í™•ì¥ì (ê¸°ë³¸ê°’: *.mp4)

### ì¤‘ë³µ ì œê±° ë§¤ê°œë³€ìˆ˜

- `--faces_dir`: ì›ë³¸ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬
- `--dedupe_dir`: ë™ì¼ ì¸ë¬¼ ê·¸ë£¹í™” í›„ ë³µì‚¬/ì €ì¥í•  ë””ë ‰í† ë¦¬
- `--representative_dir`: ëŒ€í‘œ ì–¼êµ´ë§Œ ë³„ë„ ë³µì‚¬í•  ë””ë ‰í† ë¦¬
- `--model_name`: ì–¼êµ´ ì„ë² ë”©ì— ì‚¬ìš©í•  ëª¨ë¸
  - `Facenet`: FaceNet (ê¸°ë³¸ê°’)
  - `VGG-Face`: VGG Face
  - `OpenFace`: OpenFace
  - `DeepID`: DeepID
  - `ArcFace`: ArcFace
  - `SFace`: SFace
- `--threshold`: ë™ì¼ ì¸ë¬¼ë¡œ íŒë‹¨í•  ì½”ì‚¬ì¸ ê±°ë¦¬ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.4)

### ì–¼êµ´-ìŒì„± ë§¤ì¹­ ë§¤ê°œë³€ìˆ˜

- `--image_folder`: ì–¼êµ´ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
- `--audio_folder`: ìŒì„± íŒŒì¼ í´ë” ê²½ë¡œ
- `--save_dir`: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
- `--embedding_dim`: ì„ë² ë”© ì°¨ì› (ê¸°ë³¸ê°’: 512)
- `--temperature`: InfoNCE ì˜¨ë„ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 0.07)
- `--batch_size`: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)
- `--num_epochs`: í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: 100)
- `--learning_rate`: í•™ìŠµë¥  (ê¸°ë³¸ê°’: 1e-4)
- `--audio_duration_sec`: ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ) (ê¸°ë³¸ê°’: 5)

### HQ VoxCeleb ì „ìš© ë§¤ê°œë³€ìˆ˜

- `--split_json_path`: split.json íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ./data/HQVoxCeleb/split.json)
- `--force_cpu`: ê°•ì œë¡œ CPU ì‚¬ìš©
- `--device`: ì‚¬ìš©í•  ì¥ì¹˜ (auto, cpu, cuda, ê¸°ë³¸ê°’: auto)
- `--weight_decay`: ê°€ì¤‘ì¹˜ ê°ì‡  (ê¸°ë³¸ê°’: 1e-4)
- `--save_interval`: ëª¨ë¸ ì €ì¥ ê°„ê²© (ì—í¬í¬, ê¸°ë³¸ê°’: 5)

### 5. create_matched_file.py ì‚¬ìš©ë²•

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì£¼ì–´ì§„ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ì™€ ë©”íƒ€ ì •ë³´(JSON íŒŒì¼)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,  
ê° ì¸ë±ìŠ¤ë³„ë¡œ ì–¼êµ´ ì´ë¯¸ì§€ì™€ ìŒì„± íŒŒì¼ ìŒì„ ë§¤ì¹­í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.

---

#### âœ… ì‹¤í–‰ ë°©ë²•

```bash
python scripts/create_matched_file.py \
  -d <ë°ì´í„°ì…‹_ë””ë ‰í† ë¦¬> \
  -m <ë©”íƒ€ë°ì´í„°_JSON_íŒŒì¼> \
  -o <ê²°ê³¼_ì¶œë ¥_ë””ë ‰í† ë¦¬> \
  -l <ë§¤ì¹­_í• _ìµœëŒ€_ì¸ë±ìŠ¤_ìˆ˜>
```

---

#### âœ… ì¸ì ì„¤ëª…

| ì¸ì | í•„ìˆ˜ | ì„¤ëª… |
|------|------|------|
| `-d`, `--dataset_path` | âœ… | ì–¼êµ´ ì´ë¯¸ì§€ ë° ìŒì„± íŒŒì¼ì´ ìˆëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ |
| `-m`, `--meta_path` | âœ… | ë©”íƒ€ ì •ë³´ê°€ í¬í•¨ëœ JSON íŒŒì¼ ê²½ë¡œ (`id_list` ì¶”ì¶œìš©) |
| `-o`, `--output` | âœ… | ê²°ê³¼ `.txt` íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬ |
| `-l`, `--limit` | âœ… | ì¸ë±ìŠ¤ë³„ë¡œ ë§¤ì¹­í•  ìµœëŒ€ íšŸìˆ˜ (ì˜ˆ: 100ì´ë©´ `matched_files-0.txt` ~ `matched_files-99.txt`) |

---

#### âœ… ì˜ˆì‹œ

```bash
python scripts/create_matched_file.py \
  -d data/voxceleb2/VoxCeleb2/train \
  -m data/voxceleb2/VoxCeleb2/voxceleb2-dev.json \
  -o data/output \
  -l 100
```

ìœ„ ëª…ë ¹ì€ IDë³„ë¡œ 0ë²ˆì§¸ë¶€í„° 99ë²ˆì§¸ê¹Œì§€ ì´ 100ìŒì„ ì¶”ì¶œí•˜ì—¬,  
`data/output/matched_files-0.txt`, ..., `matched_files-99.txt` í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤.

---

#### ğŸ“ ì¶œë ¥ í¬ë§·

ê° ì¶œë ¥ íŒŒì¼ (`matched_files-*.txt`)ì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤:

```
<face_image_path>    <voice_file_path>
```

ì˜ˆì‹œ:
```
data/train/id001/faces/0001/frame_0005.jpg	data/train/id001/voices/0001.wav
```

---

## ğŸš¨ ì£¼ì˜ì‚¬í•­

- ì¶œë ¥ ë””ë ‰í† ë¦¬ëŠ” ë¯¸ë¦¬ ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ (`-o` ê²½ë¡œ).
- JSON íŒŒì¼ì˜ ìµœìƒìœ„ keyë“¤ì€ ID ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤ (`dict` êµ¬ì¡°).
- `limit` ê°’ë³´ë‹¤ ê° IDì˜ face/voice ìˆ˜ê°€ ì ì„ ê²½ìš° í•´ë‹¹ ì¸ë±ìŠ¤ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.

## ë°ì´í„° êµ¬ì¡°

### ì¼ë°˜ ë°ì´í„°ì…‹ ì¶œë ¥ êµ¬ì¡°

```
output_base_dir/
â”œâ”€â”€ extracted_faces/          # ì¶”ì¶œëœ ì›ë³¸ ì–¼êµ´ ì´ë¯¸ì§€ë“¤
â”œâ”€â”€ deduped_faces/           # ì¤‘ë³µ ì œê±°ëœ ì–¼êµ´ ì´ë¯¸ì§€ë“¤ (ê·¸ë£¹í™”ë¨)
â””â”€â”€ representative_faces/    # ê° ì¸ë¬¼ ê·¸ë£¹ì˜ ëŒ€í‘œ ì–¼êµ´ë“¤
```

### HQ VoxCeleb ë°ì´í„° êµ¬ì¡°

```
data/HQVoxCeleb/
â”œâ”€â”€ vox1/
â”‚   â”œâ”€â”€ vox1_meta.csv
â”‚   â”œâ”€â”€ mel_spectograms/     # Mel spectrogram íŒŒì¼ë“¤ (.npy, .pickle)
â”‚   â””â”€â”€ masked_faces/        # ì–¼êµ´ ì´ë¯¸ì§€ë“¤ (.jpg, .png)
â”œâ”€â”€ vox2/
â”‚   â”œâ”€â”€ full_vox2_meta.csv
â”‚   â”œâ”€â”€ mel_spectograms/     # Mel spectrogram íŒŒì¼ë“¤ (.npy, .pickle)
â”‚   â””â”€â”€ masked_faces/        # ì–¼êµ´ ì´ë¯¸ì§€ë“¤ (.jpg, .png)
â””â”€â”€ split.json               # train/val/test ë¶„í•  ì •ë³´
```

### í”„ë¡œì íŠ¸ êµ¬ì¡°

```
LC_PyTorch/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ HQVoxCeleb/          # HQ VoxCeleb ë°ì´í„°ì…‹
â”‚       â”œâ”€â”€ hq_voxceleb_dataset.py
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ split.json
â”‚       â”œâ”€â”€ vox1/
â”‚       â””â”€â”€ vox2/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ hq/                  # HQ ëª¨ë¸ë“¤
â”‚   â”‚   â”œâ”€â”€ hq_voxceleb_model.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ face_voice_model.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ hq/                  # HQ ìŠ¤í¬ë¦½íŠ¸ë“¤
â”‚   â”‚   â”œâ”€â”€ train_hq_voxceleb.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ train_face_voice.py
â”‚   â””â”€â”€ evaluate_face_voice.py
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ face_voice_dataset.py
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ utils/
    â”œâ”€â”€ evaluator.py
    â”œâ”€â”€ face_extractor.py
    â””â”€â”€ face_deduplicator.py
```

### ëª¨ë¸ ì €ì¥ êµ¬ì¡°

```
saved_models/
â”œâ”€â”€ face_encoder.pth         # ì–¼êµ´ ì¸ì½”ë” ê°€ì¤‘ì¹˜
â”œâ”€â”€ face_projection.pth      # ì–¼êµ´ íˆ¬ì˜ì¸µ ê°€ì¤‘ì¹˜
â”œâ”€â”€ audio_encoder.pth        # ì˜¤ë””ì˜¤ ì¸ì½”ë” ê°€ì¤‘ì¹˜
â”œâ”€â”€ audio_projection.pth     # ì˜¤ë””ì˜¤ íˆ¬ì˜ì¸µ ê°€ì¤‘ì¹˜
â”œâ”€â”€ full_model.pth           # ì „ì²´ ëª¨ë¸ ê°€ì¤‘ì¹˜
â”œâ”€â”€ best_model.pth           # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°€ì¤‘ì¹˜
â”œâ”€â”€ config.json              # í•™ìŠµ ì„¤ì •
â”œâ”€â”€ history.json             # í•™ìŠµ íˆìŠ¤í† ë¦¬
â””â”€â”€ evaluation_results.json  # í‰ê°€ ê²°ê³¼
```

## íŒŒì¼ ëª…ëª… ê·œì¹™

- **ì›ë³¸ ì–¼êµ´**: `vid_123.jpg` (ë¹„ë””ì˜¤ íŒŒì¼ëª… ê¸°ë°˜)
- **ì¤‘ë³µ ì œê±°ëœ ì–¼êµ´**: 
  - ëŒ€í‘œ ì–¼êµ´: `vid_123.jpg`
  - ì¤‘ë³µ ì–¼êµ´: `vid_123_dedupe_vid_456.jpg`
- **ëŒ€í‘œ ì–¼êµ´**: `vid_123.jpg` (ê° ì¸ë¬¼ ê·¸ë£¹ë‹¹ í•˜ë‚˜)
- **HQ VoxCeleb**: `identity_name/mel_spectrogram.npy` ë° `identity_name/face_image.jpg`

## ëª¨ë¸ ì•„í‚¤í…ì²˜

### ì–¼êµ´-ìŒì„± ë§¤ì¹­ ëª¨ë¸

- **ì´ë¯¸ì§€ ì¸ì½”ë”**: Vision Transformer (ViT-Base)
- **ì˜¤ë””ì˜¤ ì¸ì½”ë”**: Wav2Vec2-Base
- **ì†ì‹¤ í•¨ìˆ˜**: InfoNCE (Contrastive Learning)
- **ì„ë² ë”© ì°¨ì›**: 512 (ê¸°ë³¸ê°’)

### HQ VoxCeleb ì „ìš© ëª¨ë¸

- **ì–¼êµ´ ì¸ì½”ë”**: Vision Transformer (ViT-Base) - ì‚¬ì „ í›ˆë ¨ë¨
- **ìŒì„± ì¸ì½”ë”**: Mel spectrogram ì§ì ‘ ì²˜ë¦¬ (ë™ì  íˆ¬ì˜ì¸µ)
- **íˆ¬ì˜ì¸µ**: ë™ì  ì°¨ì› â†’ 512 â†’ 512 (ReLU í™œì„±í™”)
- **ì†ì‹¤ í•¨ìˆ˜**: InfoNCE (ì–‘ë°©í–¥ ì†ì‹¤)
- **ì •ê·œí™”**: L2 ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ìš©)
- **íŠ¹ì§•**: 
  - `.npy` ë° `.pickle` íŒŒì¼ í˜•ì‹ ì§€ì›
  - ë™ì  ì…ë ¥ ì°¨ì› ì²˜ë¦¬
  - ê²€ì¦ ë°ì´í„° ì—†ìŒ ì²˜ë¦¬

### ì„±ëŠ¥ ì§€í‘œ

- **Top-1 Accuracy**: ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ë¹„ìœ¨
- **Top-5 Accuracy**: ìƒìœ„ 5ê°œ ë‚´ì— ì •ë‹µì´ í¬í•¨ë˜ëŠ” ë¹„ìœ¨
- **Top-10 Accuracy**: ìƒìœ„ 10ê°œ ë‚´ì— ì •ë‹µì´ í¬í•¨ë˜ëŠ” ë¹„ìœ¨
- **ROC-AUC Score**: ì´ì§„ ë¶„ë¥˜ ì„±ëŠ¥

## ì˜ˆì œ

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from models.face_voice_model import FaceVoiceModel
from datasets.face_voice_dataset import FaceVoiceDataset, create_data_transforms
from utils.evaluator import evaluate_summary_metrics

# ëª¨ë¸ ìƒì„±
model = FaceVoiceModel(embedding_dim=512)

# ë°ì´í„° ì¤€ë¹„
image_transform, processor = create_data_transforms()
dataset = FaceVoiceDataset(file_pairs, processor, image_transform)

# í‰ê°€
top1_accuracy, auc_score = evaluate_summary_metrics(model, dataloader, device)
```

### HQ VoxCeleb ì‚¬ìš©ë²•

```python
from models.hq.hq_voxceleb_model import HQVoxCelebModel
from data.HQVoxCeleb.hq_voxceleb_dataset import create_hq_voxceleb_dataloaders

# ë°ì´í„°ë¡œë” ìƒì„±
dataloaders = create_hq_voxceleb_dataloaders(
    split_json_path='./data/HQVoxCeleb/split.json',
    dataset_type='vox2',
    batch_size=16
)

# ëª¨ë¸ ìƒì„±
model = HQVoxCelebModel(embedding_dim=512, pretrained=True)

# í•™ìŠµ
for batch in dataloaders['train']:
    mels = batch['mel']
    faces = batch['face']
    identities = batch['identity']
    face_embeddings, audio_embeddings = model(mels, faces)
    # ì†ì‹¤ ê³„ì‚° ë° ì—­ì „íŒŒ...
```

ìì„¸í•œ ì˜ˆì œëŠ” `examples/` ë””ë ‰í† ë¦¬ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ì„±ëŠ¥ ìµœì í™” íŒ

1. **GPU ì‚¬ìš©**: CUDAê°€ ì§€ì›ë˜ëŠ” í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ë©´ ë” ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ì ì ˆí•œ ë°°ì¹˜ í¬ê¸°ë¥¼ ì„¤ì •í•˜ì„¸ìš”.
   - CPU: 4-8
   - GPU: 16-32
3. **ì„ê³„ê°’ ì¡°ì •**: `--threshold` ê°’ì„ ì¡°ì •í•˜ì—¬ ì¤‘ë³µ ì œê±°ì˜ ë¯¼ê°ë„ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   - ë‚®ì€ ê°’ (0.3): ë” ì—„ê²©í•œ ì¤‘ë³µ ì œê±°
   - ë†’ì€ ê°’ (0.5): ë” ê´€ëŒ€í•œ ì¤‘ë³µ ì œê±°
4. **ëª¨ë¸ ì„ íƒ**: ì–¼êµ´ ì„ë² ë”© ëª¨ë¸ì„ ë³€ê²½í•˜ì—¬ ì„±ëŠ¥ê³¼ ì†ë„ì˜ ê· í˜•ì„ ë§ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
5. **HQ VoxCeleb ìµœì í™”**: 
   - `--num_workers`ë¥¼ CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
   - `--audio_duration_sec`ì„ ë°ì´í„°ì— ë§ê²Œ ì¡°ì •
   - `--save_interval`ì„ í•™ìŠµ ì‹œê°„ì— ë§ê²Œ ì¡°ì •
   - macOSì—ì„œ OpenMP ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

1. **"Face could not be detected"**: ë¹„ë””ì˜¤ì˜ ì²« í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
   - í•´ê²°ì±…: ë‹¤ë¥¸ `detector_backend`ë¥¼ ì‹œë„í•˜ê±°ë‚˜ `enforce_detection=False` ì‚¬ìš©

2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œ ë°œìƒ
   - í•´ê²°ì±…: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸° ë˜ëŠ” ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í•  ì²˜ë¦¬

3. **ì„ë² ë”© ê³„ì‚° ì˜¤ë¥˜**: ì¼ë¶€ ì´ë¯¸ì§€ì—ì„œ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨
   - í•´ê²°ì±…: ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸ ë˜ëŠ” `enforce_detection=False` ì‚¬ìš©

4. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë°œìƒ
   - í•´ê²°ì±…: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°, ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ì‚¬ìš©

### HQ VoxCeleb íŠ¹í™” ë¬¸ì œ

1. **"split.json íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"**
   - í•´ê²°ì±…: `python scripts/create_voxceleb_split.py` ì‹¤í–‰

2. **"mel_spectograms ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"**
   - í•´ê²°ì±…: ë””ë ‰í† ë¦¬ëª…ì´ `mel_spectrograms`ì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •

3. **CPU ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - í•´ê²°ì±…: `--batch_size`ë¥¼ 4-8ë¡œ ì¤„ì´ê³  `--num_workers`ë¥¼ 1-2ë¡œ ì„¤ì •

4. **í•™ìŠµ ì†ë„ê°€ ëŠë¦¼**
   - í•´ê²°ì±…: GPU ì‚¬ìš© ë˜ëŠ” `--num_workers` ì¦ê°€

5. **macOS OpenMP ì˜¤ë¥˜**
   - í•´ê²°ì±…: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
   ```bash
   export KMP_DUPLICATE_LIB_OK=TRUE
   export OMP_NUM_THREADS=1
   export MKL_NUM_THREADS=1
   ```

6. **ì°¨ì› ë¶ˆì¼ì¹˜ ì˜¤ë¥˜**
   - í•´ê²°ì±…: ëª¨ë¸ì´ ë™ì ìœ¼ë¡œ ì…ë ¥ ì°¨ì›ì„ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •ë¨

7. **ê²€ì¦ ë°ì´í„° ì—†ìŒ ì˜¤ë¥˜**
   - í•´ê²°ì±…: ê²€ì¦ ë°ì´í„°ê°€ ì—†ì–´ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •ë¨

## ìµœê·¼ ì—…ë°ì´íŠ¸

### v1.0.0
- **HQ VoxCeleb ëª¨ë“ˆ ì¶”ê°€**: ì „ìš© ë°ì´í„°ì…‹ ë° ëª¨ë¸ êµ¬í˜„
- **ë””ë ‰í† ë¦¬ êµ¬ì¡° ê°œì„ **: HQ ê´€ë ¨ íŒŒì¼ë“¤ì„ ë³„ë„ ë””ë ‰í† ë¦¬ë¡œ ë¶„ë¦¬
- **ë™ì  ëª¨ë¸ ì§€ì›**: ë‹¤ì–‘í•œ ì…ë ¥ ì°¨ì›ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬
- **macOS í˜¸í™˜ì„±**: OpenMP ê´€ë ¨ ë¬¸ì œ í•´ê²°
- **íŒŒì¼ í˜•ì‹ ì§€ì› í™•ì¥**: `.npy` ë° `.pickle` íŒŒì¼ í˜•ì‹ ì§€ì›
- **ê²€ì¦ ë°ì´í„° ì²˜ë¦¬ ê°œì„ **: ê²€ì¦ ë°ì´í„°ê°€ ì—†ì–´ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬

## ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸, ê¸°ëŠ¥ ìš”ì²­, í’€ ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤.
