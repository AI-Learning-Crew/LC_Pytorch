#!/usr/bin/env python3
"""
ì–¼êµ´-ìŒì„± ë§¤ì¹­ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
"""

import argparse
import os
import sys
from pathlib import Path
import random
import numpy as np
from datetime import datetime
from zoneinfo import ZoneInfo

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import torch
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from sklearn.model_selection import train_test_split
from tqdm.auto import tqdm

try:
    from models.face_voice_model import (
        FaceVoiceModel, InfoNCELoss, save_model_components, load_model_components
    )
    from datasets.face_voice_dataset import (
        FaceVoiceDataset, collate_fn, create_data_transforms, create_audio_augmentations, match_face_voice_files
    )
except ImportError as e:
    print(f"ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    print(f"í˜„ì¬ Python ê²½ë¡œ: {sys.path}")
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print("í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”:")
    print(f"python scripts/train_face_voice.py [ì¸ìë“¤]")
    sys.exit(1)


def set_seed(seed):
    """
    ì¬í˜„ì„±ì„ ìœ„í•´ ëœë¤ ì‹œë“œë¥¼ ê³ ì •
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def save_checkpoint(epoch, model, optimizer, scheduler, best_val_loss, current_val_loss, save_dir):
    """
    í•™ìŠµ ìƒíƒœ(ìµœì‹ , ìµœê³  ì„±ëŠ¥, ì²´í¬í¬ì¸íŠ¸)ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        epoch (int): í˜„ì¬ ì—í¬í¬ ë²ˆí˜¸.
        model: ì €ì¥í•  ëª¨ë¸.
        optimizer: ì €ì¥í•  ì˜µí‹°ë§ˆì´ì €.
        scheduler: ì €ì¥í•  ìŠ¤ì¼€ì¤„ëŸ¬.
        best_val_loss (float): í˜„ì¬ê¹Œì§€ì˜ ìµœê³  ê²€ì¦ ì†ì‹¤.
        current_val_loss (float): ì´ë²ˆ ì—í¬í¬ì˜ ê²€ì¦ ì†ì‹¤.
        save_dir (str): ì €ì¥í•  ë””ë ‰í† ë¦¬.
    
    Returns:
        float: ì—…ë°ì´íŠ¸ëœ ìµœê³  ê²€ì¦ ì†ì‹¤.
    """
    # ìµœì‹  ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ ì €ì¥ (ë§¤ ì—í¬í¬ë§ˆë‹¤ ë®ì–´ì“°ê¸°)
    # ì´ íŒŒì¼ë“¤ì€ í•™ìŠµ ì¬ê°œ ì‹œ ì‚¬ìš©
    save_model_components(model, save_dir)

    # í•™ìŠµ ì¬ê°œë¥¼ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ëª¨ë¸ ê°€ì¤‘ì¹˜ ì œì™¸)
    checkpoint_path = os.path.join(save_dir, 'checkpoint.pth')
    torch.save({
        'epoch': epoch + 1,
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'best_val_loss': best_val_loss,
    }, checkpoint_path)

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    if current_val_loss < best_val_loss:
        best_val_loss = current_val_loss
        print(f"ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë°œê²¬! (Val Loss: {best_val_loss:.4f}). 'best_model/' ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.")
        best_model_dir = os.path.join(save_dir, 'best_model')
        save_model_components(model, best_model_dir)
    
    return best_val_loss

def train_model(model, train_dataloader, val_dataloader, criterion, optimizer,
                scheduler, device, num_epochs, save_dir, tensorboard_dir,
                start_epoch, best_val_loss):
    """
    ëª¨ë¸ í•™ìŠµ

    Args:
        model: í•™ìŠµí•  ëª¨ë¸
        train_dataloader: í•™ìŠµ ë°ì´í„°ë¡œë”
        val_dataloader: ê²€ì¦ ë°ì´í„°ë¡œë”
        criterion: ì†ì‹¤ í•¨ìˆ˜
        optimizer: ì˜µí‹°ë§ˆì´ì €
        device: ê³„ì‚° ì¥ì¹˜
        num_epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜
        save_dir: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        tensorboard_dir: TensorBoard ë¡œê·¸ë¥¼ ì €ì¥í•  ê²½ë¡œ. Noneì¼ ê²½ìš° ë¡œê¹…í•˜ì§€ ì•ŠìŒ
        start_epoch: í•™ìŠµì„ ì‹œì‘í•  ì—í¬í¬ ë²ˆí˜¸. í•™ìŠµ ì¬ê°œ ì‹œ ì‚¬ìš©
        best_val_loss: ì´ì „ í•™ìŠµì—ì„œ ê¸°ë¡ëœ ê°€ì¥ ë‚®ì€ ê²€ì¦ ì†ì‹¤ ê°’. í•™ìŠµ ì¬ê°œ ì‹œ ì‚¬ìš©

    Returns:
        í•™ìŠµ íˆìŠ¤í† ë¦¬
    """
    history = {'train_loss': [], 'val_loss': []}

    # TensorBoard ì„¤ì •
    writer = SummaryWriter(tensorboard_dir) if tensorboard_dir else None 
    if writer:
        print(f"TensorBoard ë¡œê·¸ê°€ '{tensorboard_dir}'ì— ì €ì¥ë©ë‹ˆë‹¤.")
        print(f"ì‹¤í–‰: tensorboard --logdir={os.path.dirname(tensorboard_dir)}")

    # í•™ìŠµ ì¬ê°œë¥¼ ìœ„í•´ global_step ì´ˆê¸°í™”
    global_step = start_epoch * len(train_dataloader)

    for epoch in range(start_epoch, num_epochs):
        # í•™ìŠµ ëª¨ë“œ
        model.train()
        train_loss = 0.0

        train_pbar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')
        for images, audios in train_pbar:
            images, audios = images.to(device), audios.to(device)

            # ìˆœì „íŒŒ
            image_embeddings, audio_embeddings = model(images, audios)
            loss = criterion(image_embeddings, audio_embeddings)

            # ì—­ì „íŒŒ
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})

            # TensorBoardì— ë°°ì¹˜ë³„ ì†ì‹¤ ê¸°ë¡
            if writer:
                writer.add_scalar('Loss/Train_Batch', loss.item(), global_step)

            global_step += 1

        train_loss /= len(train_dataloader)
        history['train_loss'].append(train_loss)

        # ê²€ì¦ ëª¨ë“œ
        model.eval()
        val_loss = 0.0

        with torch.no_grad():
            val_pbar = tqdm(val_dataloader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')
            for images, audios in val_pbar:
                images, audios = images.to(device), audios.to(device)

                image_embeddings, audio_embeddings = model(images, audios)
                loss = criterion(image_embeddings, audio_embeddings)

                val_loss += loss.item()
                val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})

        val_loss /= len(val_dataloader)
        history['val_loss'].append(val_loss)

        # ë§¤ ì—í¬í¬ê°€ ëë‚œ í›„ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ step()ì„ í˜¸ì¶œí•˜ì—¬ í•™ìŠµë¥ ì„ ì—…ë°ì´íŠ¸
        scheduler.step()

        # ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ ëª¨ë“  ê·¸ë£¹ì˜ í•™ìŠµë¥  ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
        lrs = scheduler.get_last_lr()

        # ê·¸ë£¹ë³„ í•™ìŠµë¥  ëª…ì‹œ
        lr_info = (f"Pretrained: {lrs[0]:.7f}, "
                   f"Projection: {lrs[1]:.7f}")
        # í•™ìŠµ ì§„í–‰ ìƒí™© ì¶œë ¥
        print(f"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LRs: [{lr_info}]")

        # í•™ìŠµ ìƒíƒœ(ìµœì‹ , ìµœê³  ì„±ëŠ¥, ì²´í¬í¬ì¸íŠ¸)ë¥¼ í•œ ë²ˆì— ì €ì¥
        best_val_loss = save_checkpoint(
            epoch=epoch,
            model=model,
            optimizer=optimizer,
            scheduler=scheduler,
            best_val_loss=best_val_loss,
            current_val_loss=val_loss,
            save_dir=save_dir
        )

        # TensorBoardì— ì—í¬í¬ë³„ ë©”íŠ¸ë¦­ ê¸°ë¡
        if writer:
            # í›ˆë ¨ ë° ê²€ì¦ ì†ì‹¤ ê¸°ë¡
            writer.add_scalar('Loss/Train_Epoch', train_loss, epoch)
            writer.add_scalar('Loss/Val_Epoch', val_loss, epoch)

            # ê·¸ë£¹ë³„ í•™ìŠµë¥ ì„ êµ¬ë¶„í•˜ì—¬ ê¸°ë¡
            writer.add_scalar('Learning_Rate/Pretrained', lrs[0], epoch)
            writer.add_scalar('Learning_Rate/Projection', lrs[1], epoch)

            # ëª¨ë¸ íŒŒë¼ë¯¸í„° ë° ê·¸ë˜ë””ì–¸íŠ¸ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ (ë§¤ 10 ì—í¬í¬ë§ˆë‹¤)
            if (epoch + 1) % 10 == 0:
                for name, param in model.named_parameters():
                    if param.requires_grad:
                        writer.add_histogram(f'Parameters/{name}', param.data, epoch)
                        if param.grad is not None:
                            writer.add_histogram(f'Gradients/{name}', param.grad, epoch)

    # TensorBoard ì¢…ë£Œ
    if writer:
        writer.close()
        print(f"TensorBoard ë¡œê·¸ê°€ '{tensorboard_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return history


def main():
    parser = argparse.ArgumentParser(description='ì–¼êµ´-ìŒì„± ë§¤ì¹­ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.')

    # ë°ì´í„° ê²½ë¡œ
    parser.add_argument('--image_folder', type=str, required=True,
                       help='ì–¼êµ´ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ')
    parser.add_argument('--audio_folder', type=str, required=True,
                       help='ìŒì„± íŒŒì¼ í´ë” ê²½ë¡œ')
    parser.add_argument('--save_dir', type=str, required=True,
                       help='ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬')

    # ëª¨ë¸ ì„¤ì •
    parser.add_argument('--embedding_dim', type=int, default=512,
                       help='ì„ë² ë”© ì°¨ì› (ê¸°ë³¸ê°’: 512)')
    parser.add_argument('--temperature', type=float, default=0.07,
                       help='InfoNCE ì˜¨ë„ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 0.07)')

    # í•™ìŠµ ì„¤ì •
    parser.add_argument('--batch_size', type=int, default=32,
                       help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)')
    parser.add_argument('--num_epochs', type=int, default=100,
                       help='í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: 100)')
    parser.add_argument('--learning_rate', type=float, default=1e-3,
                        help='(ì‹ ê·œ ë ˆì´ì–´ìš©) ê¸°ë³¸ í•™ìŠµë¥  (ê¸°ë³¸ê°’: 1e-3)')
    # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ìœ„í•œ í•™ìŠµë¥  ì¸ì
    parser.add_argument('--pretrained_lr', type=float, default=1e-5,
                        help='ì‚¬ì „ í•™ìŠµëœ ë ˆì´ì–´ì˜ í•™ìŠµë¥  (ê¸°ë³¸ê°’: 1e-5)')
    parser.add_argument('--test_size', type=float, default=0.2,
                       help='í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)')
    parser.add_argument('--random_state', type=int, default=42,
                       help='ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)')
    parser.add_argument('--disable_image_augmentation', action='store_true',
                        help='ì´ë¯¸ì§€ ë°ì´í„° ì¦ê°•ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.')
    parser.add_argument('--disable_audio_augmentation', action='store_true',
                        help='ì˜¤ë””ì˜¤ ë°ì´í„° ì¦ê°•ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.')


    # ì˜¤ë””ì˜¤ ì„¤ì •
    parser.add_argument('--audio_duration_sec', type=int, default=5,
                       help='ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ) (ê¸°ë³¸ê°’: 5)')
    parser.add_argument('--target_sr', type=int, default=16000,
                       help='ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ê¸°ë³¸ê°’: 16000)')

    # íŒŒì¼ ë§¤ì¹­ ì„¤ì •
    parser.add_argument('--skip_file_matching', action='store_true',
                       help='íŒŒì¼ ë§¤ì¹­ ê³¼ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤ (ì´ë¯¸ ë§¤ì¹­ëœ íŒŒì¼ ëª©ë¡ì´ ìˆëŠ” ê²½ìš°)')
    parser.add_argument('--matched_files_path', type=str, default=None,
                       help='ì´ë¯¸ ë§¤ì¹­ëœ íŒŒì¼ ëª©ë¡ì´ ì €ì¥ëœ ê²½ë¡œ (JSON íŒŒì¼)')

    # TensorBoard ì„¤ì •
    parser.add_argument('--tensorboard_dir', type=str, default=None,
                       help='TensorBoard ë¡œê·¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: save_dir/runs)')
    parser.add_argument('--no_tensorboard', action='store_true',
                       help='TensorBoard ë¡œê¹…ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤')
    
    # í•™ìŠµ ì¬ê°œ ì„¤ì •
    parser.add_argument('--resume_dir', type=str, default=None,
                        help='ì¬ê°œí•  í•™ìŠµì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: saved_models/20250819_122430)')

    args = parser.parse_args()

    # --- ì´ˆê¸° ì„¤ì • ---
    set_seed(args.random_state)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ì¥ì¹˜: {device}")

    # --- ê²½ë¡œ ì„¤ì • ---
    start_epoch = 0
    best_val_loss = float('inf')
    if args.resume_dir:
        # ì¬ê°œ ëª¨ë“œ: ì§€ì •ëœ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        final_save_dir = args.resume_dir
        if not os.path.exists(final_save_dir):
            print(f"âŒ ì˜¤ë¥˜: í•™ìŠµì„ ì¬ê°œí•  ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {final_save_dir}")
            return 1
        print(f"í•™ìŠµì„ ì¬ê°œí•©ë‹ˆë‹¤. ì €ì¥ ë””ë ‰í† ë¦¬: {final_save_dir}")
    else:
        # ì‹ ê·œ í•™ìŠµ ëª¨ë“œ: í•œêµ­ ì‹œê°„(KST) ê¸°ì¤€ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ë””ë ‰í† ë¦¬ ìƒì„±
        KST = ZoneInfo("Asia/Seoul")
        timestamp = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        final_save_dir = os.path.join(args.save_dir, timestamp)
        os.makedirs(final_save_dir, exist_ok=True)
        print(f"ìƒˆë¡œìš´ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. ì €ì¥ ë””ë ‰í† ë¦¬: {final_save_dir}")

    # TensorBoard ë””ë ‰í† ë¦¬ ì„¤ì •
    tensorboard_dir = None if args.no_tensorboard else os.path.join(final_save_dir, 'runs')

    # --- ë°ì´í„° ì¤€ë¹„ ---

    # ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(args.image_folder):
        print(f"âŒ ì˜¤ë¥˜: ì´ë¯¸ì§€ í´ë” '{args.image_folder}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return 1

    if not os.path.exists(args.audio_folder):
        print(f"âŒ ì˜¤ë¥˜: ì˜¤ë””ì˜¤ í´ë” '{args.audio_folder}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return 1

    # íŒŒì¼ ë§¤ì¹­ (ì„ íƒì )
    if args.skip_file_matching:
        if args.matched_files_path and os.path.exists(args.matched_files_path):
            import json
            print(f"ì €ì¥ëœ íŒŒì¼ ë§¤ì¹­ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {args.matched_files_path}")
            with open(args.matched_files_path, 'r', encoding='utf-8') as f:
                matched_files = json.load(f)
            print(f"ì´ {len(matched_files)}ê°œì˜ ë§¤ì¹­ëœ íŒŒì¼ ìŒì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        else:
            print(f"âŒ ì˜¤ë¥˜: --skip_file_matchingì´ ì„¤ì •ë˜ì—ˆì§€ë§Œ ìœ íš¨í•œ --matched_files_pathê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return 1
    else:
        print("íŒŒì¼ ë§¤ì¹­ ì¤‘...")
        matched_files = match_face_voice_files(args.image_folder, args.audio_folder)
        print(f"ì´ {len(matched_files)}ê°œì˜ ë§¤ì¹­ëœ íŒŒì¼ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        # ë§¤ì¹­ ê²°ê³¼ ì €ì¥ (ì„ íƒì )
        if args.matched_files_path:
            import json
            os.makedirs(os.path.dirname(args.matched_files_path), exist_ok=True)
            with open(args.matched_files_path, 'w', encoding='utf-8') as f:
                json.dump(matched_files, f, ensure_ascii=False, indent=2)
            print(f"íŒŒì¼ ë§¤ì¹­ ê²°ê³¼ê°€ '{args.matched_files_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if len(matched_files) == 0:
        print(f"âŒ ì˜¤ë¥˜: ë§¤ì¹­ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return 1
    
    # ë°ì´í„° ë¶„í• 
    train_files, val_files = train_test_split(
        matched_files,
        test_size=args.test_size,
        random_state=args.random_state
    )
    print(f"í•™ìŠµ ë°ì´í„°: {len(train_files)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(val_files)}ê°œ")
    
    # ë°ì´í„° ë³€í™˜ê¸° ë° ì¦ê°• íŒŒì´í”„ë¼ì¸ ìƒì„±
    image_transform, processor = create_data_transforms(
        use_augmentation=not args.disable_image_augmentation
    )
    audio_augmentations = create_audio_augmentations(
        sample_rate=args.target_sr,
        use_augmentation=not args.disable_audio_augmentation
    )

    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = FaceVoiceDataset(
        train_files, processor, image_transform,
        audio_augmentations=audio_augmentations,
        audio_duration_sec=args.audio_duration_sec,
        target_sr=args.target_sr
    )
    val_dataset = FaceVoiceDataset(
        val_files, processor, create_data_transforms(use_augmentation=False)[0],
        audio_augmentations=None,
        audio_duration_sec=args.audio_duration_sec,
        target_sr=args.target_sr
    )
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=4
    )
    val_dataloader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=4
    )

    # --- ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„ ---
    print("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model = FaceVoiceModel(embedding_dim=args.embedding_dim)
    model.to(device)

    # ì°¨ë“± í•™ìŠµë¥ ì„ ì ìš©í•œ ì˜µí‹°ë§ˆì´ì € ìƒì„±
    # ì‚¬ì „ í•™ìŠµëœ ì¸ì½”ë”(ViT, Wav2Vec2) íŒŒë¼ë¯¸í„°
    pretrained_params = list(model.image_encoder.parameters()) + list(model.audio_encoder.parameters())
    # ì²˜ìŒë¶€í„° í•™ìŠµí•´ì•¼ í•˜ëŠ” í”„ë¡œì ì…˜ ë ˆì´ì–´ íŒŒë¼ë¯¸í„°
    projection_params = list(model.image_projection.parameters()) + list(model.audio_projection.parameters())

    # ê° ê·¸ë£¹ì— ë‹¤ë¥¸ í•™ìŠµë¥ ì„ ì„¤ì •í•˜ì—¬ ì˜µí‹°ë§ˆì´ì € ìƒì„±
    optimizer = torch.optim.AdamW([
        {'params': pretrained_params, 'lr': args.pretrained_lr},  # ì‚¬ì „ í•™ìŠµëœ ë¶€ë¶„ì€ ë‚®ì€ í•™ìŠµë¥ ë¡œ ë¯¸ì„¸ ì¡°ì •
        {'params': projection_params, 'lr': args.learning_rate}   # ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„ì€ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ í•™ìŠµë¥ ë¡œ ë¹ ë¥´ê²Œ í•™ìŠµ
    ])

    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=args.num_epochs, # ì „ì²´ ì—í¬í¬ ìˆ˜
        eta_min=1e-7          # ë„ë‹¬í•  ìµœì†Œ í•™ìŠµë¥ 
    )

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    if args.resume_dir:
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” í•­ìƒ ì»´í¬ë„ŒíŠ¸ íŒŒì¼ì—ì„œ ë¡œë“œ
        print(f"ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {final_save_dir}")
        model = load_model_components(model, final_save_dir, device)
        if model is None:
            print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return 1
        
        checkpoint_path = os.path.join(args.resume_dir, 'checkpoint.pth')
        if os.path.exists(checkpoint_path):
            print(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {checkpoint_path}")
            checkpoint = torch.load(checkpoint_path, map_location=device)
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            start_epoch = checkpoint['epoch']
            best_val_loss = checkpoint['best_val_loss']
            print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ. Epoch {start_epoch}ë¶€í„° í•™ìŠµì„ ì¬ê°œí•©ë‹ˆë‹¤.")
            print(f"   (ì´ì „ ìµœê³  Val Loss: {best_val_loss:.4f})")
        else:
            print(f"âŒ ì˜¤ë¥˜: --resume_dirì´ ì§€ì •ë˜ì—ˆì§€ë§Œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ '{checkpoint_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 1

    # --- í•™ìŠµ ì‹¤í–‰ ---
    print("í•™ìŠµ ì‹œì‘...")
    history = train_model(
        model, train_dataloader, val_dataloader,
        InfoNCELoss(args.temperature),
        optimizer, scheduler, device, args.num_epochs, 
        final_save_dir, tensorboard_dir, start_epoch, best_val_loss
    )

    print(f"í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ '{final_save_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    if tensorboard_dir:
        print(f"TensorBoard ë¡œê·¸ í™•ì¸: tensorboard --logdir={os.path.dirname(tensorboard_dir)}")
    return 0


if __name__ == '__main__':
    sys.exit(main())
